<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-6 {
     width: 16.6%;
     float: left;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: left;
    margin-top: 8px;
    margin-bottom: 8px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}

.supp-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}



.topnav {
  overflow: hidden;
  background-color: #EEEEEE;
}

.topnav a {
  float: left;
  color: black;
/*   text-align: center; */
  padding: 10px 12px;
  text-decoration: none;
  font-size: 12px;
}

.centered {
  display: block;
  margin-left: auto;
  margin-right: auto;
}


</style>


<div class="topnav" id="myTopnav">
  <a href="https://www.polyu.edu.hk/en/"><img width="25%" src="assets/logo_polyu.png"></a>
</div>


<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes</title>
    <meta property="og:description" content="SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141699104-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-141699104-1');
    </script>
</head>


<body>
<div class="container">
    <div class="paper-title">
        <h1>SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes</h1>
    </div>
    
    <div id="authors">
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://xiaokangwei.github.io/">Xiaokang Wei</a><sup>1,2</sup></div>
            <div class="col-3 text-center"><a href="https://zhuomanliu.tech/">Zhuoman Liu</a><sup>1</sup></div>
            <div class="col-3 text-center"><a href="https://scholar.google.com.hk/citations?user=mQ9YyHsAAAAJ&hl=en">Ping Li</a><sup>1</sup></div>
            <div class="col-3 text-center"><a href="https://scholar.google.com/citations?user=yRMNWQ0AAAAJ&hl=en">Yan Luximon</a><sup>1,2</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-2 text-center"><sup>1</sup> The Hong Kong Polytechnic University</a></div>
            <div class="col-2 text-center"><sup>2</sup> Laboratory for Artificial Intelligence in Design, HKSAR</div>
        </div>
        <div class="affil-row">
            <div class="venue text-center"><b>ICME 2025</b></div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="http://arxiv.org/abs/2402.06136">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
<!--             <a class="supp-btn" href="http://arxiv.org/abs/2402.06136">
                <span class="material-icons"> description </span> 
                 arXiv
            </a> -->
            <a class="supp-btn" href="assets/SIR_bib.txt">
                <span class="material-icons"> description </span> 
                 BibTeX
            </a>
            <a class="supp-btn" href="https://github.com/XiaokangWei/SIR/">
                <span class="material-icons"> description </span> 
                 Code
            </a>   
            <a class="supp-btn" href="https://github.com/XiaokangWei/SIR/">
                <span class="material-icons"> description </span> 
                 Dataset
            </a>   
            </div>
        </div>
    </div>

    <section id="teaser-videos">
        <div class="flex-row">
            <figure style="width: 33%; float: left">
                <video class="centered" width="100%" controls muted loop autoplay>
                    <source src="assets/1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
            
            <figure style="width: 33%; float: left">
                <video class="centered" width="100%" controls muted loop autoplay>
                    <source src="assets/3.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
            
            <figure style="width: 33%; float: left">
                <video class="centered" width="100%" controls muted loop autoplay>
                    <source src="assets/2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>
        </div>
    </section>


    <section id="abstract"/>
        <h1>Abstract</h1>
        <hr>
        <p>We propose <strong>SIR</strong>, an efficient method to <strong>decompose differentiable shadows</strong> for inverse rendering on indoor scenes using multi-view data, addressing the challenges in accurately decomposing the materials and lighting conditions. Unlike previous methods that struggle with shadow fidelity in complex lighting environments, our approach explicitly learns shadows for enhanced realism in material estimation <strong>under unknown light positions</strong>. Utilizing posed HDR images as input, SIR employs an SDF-based neural radiance field for comprehensive scene representation. Then, SIR integrates a shadow term with a <strong>three-stage material estimation</strong> approach to improve SVBRDF quality. Specifically, SIR is designed to learn a <strong>differentiable shadow</strong>, complemented by <strong>BRDF regularization</strong>, to optimize inverse rendering accuracy. Extensive experiments on both synthetic and real-world indoor scenes demonstrate the superior performance of SIR over existing methods in both quantitative metrics and qualitative analysis. The significant decomposing ability of SIR enables sophisticated editing capabilities like <strong>free-view relighting, object insertion, and material replacement</strong>.
        </p>

        <figure style="width: 100%;">
            <a>
                <img width="50%" src="assets/teaser.png" class="centered">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
            <strong>Figure 1:</strong> Given a set of posed multi-view HDR images of an indoor scene, SIR successfully disentangles the scene appearance into 3D neural fields of shape, global and spatially-varying illumination, soft shadows, and SVBRDFs, which can produce convincing results for several applications such as novel view synthesis, free-viewpoint relighting, object insertion, and material replacement.
        </figure>

        <figure style="width: 100%; float: center">
            <a>
                <img width="90%" src="assets/model.png" class="centered">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
            <strong>Figure 2:</strong> The pipeline consists of three phases: 1) In phase 1, we sample a ray with direction  <strong>v</strong>  and spatial point <strong>x</strong> from the given posed HDR images. The geometry network  <var>f<sub>d</sub></var>  learns the signed distance  <var>d</var>  , and the HDR-radiance network  <var>f<sub>c</sub></var>  learns radiance  <var>C</var>  . Ray marching is then employed to obtain the surface point  <strong>x^</strong>  . 2) In phase 2, we sample diffuse incoming light  <var>L<sub>i,d</sub></var>  from environment maps  <var>E</var>  for learning irradiance  <var>I<sub>ir</sub></var>  . We also calculate the specular incoming light  <var>L<sub>i,s</sub></var>  and the pseudo hard shadow  <var>ξ</var>  . 3) In phase 3, hard shadow  <var>S<sub>hard</sub></var>  is learned using <var>Θ<sub>h</sub></var> with pseudo ground truth. We then initialize the parameters of  <var>Θ<sub>s</sub></var>  using the optimized parameters of  <var>Θ<sub>h</sub></var>  . Instance-level BRDF regularizers are applied, and the whole rendering equation is optimized to update the soft shadow  <var>S<sub>soft</sub></var>  , albedo  <var>A^</var>  , and roughness  <var>R^</var>  .
            </p>
        </figure>

    </section>

    <section id="results">
        <h1>Results</h1>
        <h2>Comparison with Baselines</h2>
        <hr>
        <figure style="width: 100%;">
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/baseline_albedo.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <hr>
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/baseline_roughness.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <hr>
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/viewSynthetic.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px;">
            <strong> Results on predicted albedo, roughness and synthetic image.</strong> 
            Despite tackling a more challenging task, our SIR outperforms existing methods in decomposing material attributes like albedo and roughness, and more notably, in shadow extraction. our method exhibits a remarkable capability to handle complex lighting conditions in real-world indoor scenes. This ability is crucial for achieving precise and reliable material estimations for inverse rendering.
            </p>
        </figure>
        
        <hr>
        <h2>Ablation Study</h2>
        <figure style="width: 100%;">
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/ablationStudy.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px;">
            <strong> Results of ablation study on evaluating the impact of shadow terms, differentiable soft shadow, and albedo regularizer. </strong> 
            </p>
        </figure>

        <h2>Editing Applications</h2>
        <figure style="width: 100%;">
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/editing.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px;">
            <strong> Results of virtual object insertion on synthetic and real-world scenes. </strong> Our method generalizes well to synthetic and real-world scenes and consistently produces realistic appearance and shadows.
            </p>
        </figure>
        

    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@misc{wei2024sir,
      title={SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes}, 
      author={Xiaokang Wei and Zhuoman Liu and Yan Luximon},
      year={2024},
      eprint={2402.06136},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <img class="screenshot" src="assets/paper_preview.png"></a>
            </div>
            <div style="width: 55%">
                <p><b>SIR: Multi-view Inverse Rendering with Decomposable Shadow for Indoor Scenes</b></p>
                <p>Xiaokang Wei, Zhuoman Liu, Yan Luximon</p>
                <div><span class="material-icons"> description </span><a href="http://arxiv.org/abs/2402.06136"> arXiv </a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/SIR_bib.txt"> BibTeX</a></div>
            </div>
        </div>
    </section>

</div>
</body>
</html>
